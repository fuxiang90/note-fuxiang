看着目录回忆今天所看的内容


### 第三章
* 爬虫 ，分布式爬虫 ，如何更好的利用 带宽
* 网站更新如何处理
>1. 向网站 发送请求询问是否有更新
* 垂直的爬虫 ，对于某个主题的爬取，这里就涉及到分类了

* bigtable ,针对随机读，顺序写 ，几乎不修改 而设计的一个分布式数据库
* 压缩 ，索引 的压缩

* 重复性检测 ，几个算法
>1. 用向量的方式 
>2. 校验和
>3. 指纹 simhash 算法

* 去除噪声 ，根据每行出现的html 标签的个数

### 第五章
这一章看的不是很仔细，主要是将如何建立倒排表，并根据查询对文档进行排序
排序的依据 基本上是以词频
* 倒排表 term -> (docid ,pos) (docid ,pos)
>1. 一般都是采取这样的方式，那么对于如何存储，就有很多压缩算法了，没有太去在意这个压缩算法
* 索引构建 并行 分布式 或者考虑以后的索引合并 ，这个倒比较好理解
* 查询处理 ，对于doc at a time 和 term at a time 
> 一般都是先查询倒排表然后得到doc list ，然后再进行评分
